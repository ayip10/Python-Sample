# -*- coding: utf-8 -*-
"""HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pMwf-OJFZtAuhoPDloo2iGv3d-e0051d
"""

import nltk
import pandas as pd
# download the nltk data
nltk.download('punkt')
from nltk.tokenize import sent_tokenize, word_tokenize

#reading in data
df = pd.read_csv('https://raw.githubusercontent.com/lkyin/ECS189L/main/Tweets.csv')

df.columns = ['tweet_id','airline_sentiment','airline_sentiment_confidence','negativereason','negativereason_confidence','airline','airline_sentiment_gold','name','negativereason_gold','retweet_count','text','tweet_coord','tweet_created','tweet_location','user_timezone']
#'tweet_id', 'sentiment', 'sentiment_confidence_score', 'negative_reason', 'negative_reason_confidence', 'airline', 'sentiment_gold', 'name', 'retweet_count', 'tweet_text', 'tweet_coordinates', 'time_of_tweet', 'date_of_tweet', 'tweet_location', 'user_time_zone'

#stopword removal

from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

stopwords.words('english')
stop_words = set(stopwords.words('english'))
stop_words.add('@virginamerica')
stop_words.add('@AmericanAir')
stop_words.add('@AmericanAirlines')
stop_words.add('@SouthwestAir')
stop_words.add('@united')
stop_words.add('@JetBlue')
stop_words.add('JetBlue')
stop_words.add('i')
stop_words.add('s')
stop_words.add('')
stop_words.add('http')
stop_words.add('usairways')

lower_stopwords = []

#make stopwords lowercase
for item in stop_words:
    lower_stopwords.append(item.lower())

import string
#lowercase all words in df['text']
df['text'] = df['text'].apply(lambda x: x.lower())
df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word != '']))
#getting rid of stopwords
df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (string.punctuation and lower_stopwords)]))
#df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (lower_stopwords)]))
#tokenizing words
df['text'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)
df['text']

import itertools
import collections
import string

flatList = list(itertools.chain(*df['text']))
#get rid of empty string
flatList = [''.join(c for c in s if c not in string.punctuation) for s in flatList if s not in (lower_stopwords)]
flatList = [i for i in flatList if i != '']
#getting rid of numbers
flatList = [item for item in flatList if not item.isdigit()]
countList = collections.Counter(flatList).most_common(10)

"""##1. Top 10 words in tweets for each sentiment group (shown below)"""

#top 10 words for negative tweet sentiment

list_negative = df['text'].loc[df['airline_sentiment'] == 'negative']

list_negative = list(itertools.chain(*list_negative))
list_negative = [i for i in flatList if i != '']
list_negative = [''.join(c for c in s if c not in string.punctuation) for s in list_negative if s not in (lower_stopwords)]
list_negative = [i for i in list_negative if not i.isdigit()]
list_negative = [i for i in list_negative if len(i)!=1]

count_list_negative = collections.Counter(list_negative).most_common(10)
# countList
count_list_negative

#top 10 words for positive tweet sentiment

list_positive = df['text'].loc[df['airline_sentiment'] == 'positive']

list_positive = list(itertools.chain(*list_positive))
list_positive = [''.join(c for c in s if c not in string.punctuation) for s in list_positive if s not in (lower_stopwords)]
list_positive = [i for i in list_positive if i != '']
list_positive = [i for i in list_positive if len(i)!=1]

count_list_positive = collections.Counter(list_positive).most_common(10)
# countList
count_list_positive

#top 10 words for neutral tweet sentiment

list_neutral = df['text'].loc[df['airline_sentiment'] == 'neutral']

list_neutral = list(itertools.chain(*list_neutral))
list_neutral = [''.join(c for c in s if c not in string.punctuation) for s in list_neutral if s not in (lower_stopwords)]
list_neutral = [i for i in list_neutral if i != '']
list_neutral = [i for i in list_neutral if len(i)!=1]

count_list_neutral = collections.Counter(list_neutral).most_common(10)
# countList
count_list_neutral

"""##Part 2: Train a classification model of sentiment as a function of the tweet text. You can use any classification method we studied (no neural nets or others we haven't studied). Use 80% of the data rows for training, and the rest 20% for testing (careful, sample randomly as the tweets are ordered by airline and you want to make sure each airline is represented in both the training and test data). Then, process the text data using best practices in NLP text processing, e.g., eliminate airline names and @-words, any special character words, as well as stop words and punctuation. You may want to lowercase all the words too. If you want to go the extra step, you can use POS-tagging and lemmatization.
##What to report: Accuracy of your best model on the test data.
"""

import pandas as pd
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
np.set_printoptions(precision=3)

#shuffle rows of dataframe
df = df.sample(frac = 1)
corpus = df['text'].apply(lambda x: ' '.join([word for word in x]))
vectorizer = TfidfVectorizer()
#X = vectorizer.fit_transform(corpus)[35000:]
X = vectorizer.fit_transform(corpus)
corpus

import scipy.stats as stats
from sklearn.model_selection import train_test_split
y = df['airline_sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(C=1000, solver='lbfgs', penalty='l2')
model.fit(X_train,y_train)
#done training
y_pred = model.predict(X_test)

model.score(X,y)

"""##Accuracy of best model: 0.942964480874317

##Part 3: Rank the different airlines in two ways. First, in terms of the fraction of positive tweets. And second, in terms of the fraction of negative tweets.

##What to report: The top 3 airlines in terms of the fraction of positive tweets. And, the top 3 airlines in terms of the fraction of negative tweets.
"""

airlines = df.airline.unique()
airlines

index_american_total = len(df['text'].loc[(df['airline']=='American')])
index_american_total

index_american_pos = df['text'].loc[(df['airline_sentiment'] == 'positive')].loc[(df['airline']=='American')]
index_american_neutral = df['text'].loc[(df['airline_sentiment'] == 'neutral')].loc[(df['airline']=='American')]
index_american_negative = df['text'].loc[(df['airline_sentiment'] == 'negative')].loc[(df['airline']=='American')]

print("American positive: ", len(index_american_pos)/index_american_total)
print("American neutral: ",len(index_american_neutral)/index_american_total)
print("American negative: ",len(index_american_negative)/index_american_total)

"""The percentage of positive airline tweets from American is 0.12178325480246466

The percentage of neutral airline tweets from American is 0.16781442551649148

The percentage of positive airline tweets from American is 0.7104023196810438

"""

index_vm_total = len(df['text'].loc[(df['airline']=='Virgin America')])
index_vm_total

index_vm_pos = df['text'].loc[(df['airline_sentiment'] == 'positive')].loc[(df['airline']=='Virgin America')]
index_vm_neutral = df['text'].loc[(df['airline_sentiment'] == 'neutral')].loc[(df['airline']=='Virgin America')]
index_vm_negative = df['text'].loc[(df['airline_sentiment'] == 'negative')].loc[(df['airline']=='Virgin America')]

print("Virgin America positive: ", len(index_vm_pos)/index_vm_total)
print("Virgin America neutral: ",len(index_vm_neutral)/index_vm_total)
print("Virgin America negative: ",len(index_vm_negative)/index_vm_total)

"""The percentage of positive airline tweets from Virgin America is 0.30158730158730157

The percentage of neutral airline tweets from Virgin America is 0.3392857142857143

The percentage of positive airline tweets from Virgin America is 0.35912698412698413

"""

index_united_total = len(df['text'].loc[(df['airline']=='United')])

index_united_pos = df['text'].loc[(df['airline_sentiment'] == 'positive')].loc[(df['airline']=='United')]
index_united_neutral = df['text'].loc[(df['airline_sentiment'] == 'neutral')].loc[(df['airline']=='United')]
index_united_negative = df['text'].loc[(df['airline_sentiment'] == 'negative')].loc[(df['airline']=='United')]

print("United positive: ", len(index_united_pos)/index_united_total)
print("United neutral: ",len(index_united_neutral)/index_united_total)
print("United negative: ",len(index_united_negative)/index_united_total)

"""The percentage of positive airline tweets from United is 0.30158730158730157

The percentage of neutral airline tweets from United is 0.3392857142857143

The percentage of positive airline tweets from United is 0.35912698412698413

"""

index_south_total = len(df['text'].loc[(df['airline']=='Southwest')])

index_south_pos = df['text'].loc[(df['airline_sentiment'] == 'positive')].loc[(df['airline']=='Southwest')]
index_south_neutral = df['text'].loc[(df['airline_sentiment'] == 'neutral')].loc[(df['airline']=='Southwest')]
index_south_negative = df['text'].loc[(df['airline_sentiment'] == 'negative')].loc[(df['airline']=='Southwest')]

print("Southwest positive: ", len(index_south_pos)/index_south_total)
print("Southwest neutral: ",len(index_south_neutral)/index_south_total)
print("Southwest negative: ",len(index_south_negative)/index_south_total)

"""The percentage of positive airline tweets from Southwest is 0.30158730158730157

The percentage of neutral airline tweets from Southwest is 0.3392857142857143

The percentage of positive airline tweets from Southwest is 0.35912698412698413
"""

index_delta_total = len(df['text'].loc[(df['airline']=='Delta')])

index_delta_pos = df['text'].loc[(df['airline_sentiment'] == 'positive')].loc[(df['airline']=='Delta')]
index_delta_neutral = df['text'].loc[(df['airline_sentiment'] == 'neutral')].loc[(df['airline']=='Delta')]
index_delta_negative = df['text'].loc[(df['airline_sentiment'] == 'negative')].loc[(df['airline']=='Delta')]

print("Delta positive: ", len(index_delta_pos)/index_delta_total)
print("Delta neutral: ",len(index_delta_neutral)/index_delta_total)
print("Delta negative: ",len(index_delta_negative)/index_delta_total)

"""The percentage of positive airline tweets from Delta is 0.30158730158730157

The percentage of neutral airline tweets from Delta is 0.3392857142857143

The percentage of positive airline tweets from Delta is 0.35912698412698413
"""

index_airways_total = len(df['text'].loc[(df['airline']=='US Airways')])

index_airways_pos = df['text'].loc[(df['airline_sentiment'] == 'positive')].loc[(df['airline']=='US Airways')]
index_airways_neutral = df['text'].loc[(df['airline_sentiment'] == 'neutral')].loc[(df['airline']=='US Airways')]
index_airways_negative = df['text'].loc[(df['airline_sentiment'] == 'negative')].loc[(df['airline']=='US Airways')]

print("US Airways positive: ", len(index_airways_pos)/index_airways_total)
print("US Airways neutral: ",len(index_airways_neutral)/index_airways_total)
print("US Airways negative: ",len(index_airways_negative)/index_airways_total)

"""The percentage of positive airline tweets from US Airways is 0.09234466186062479

The percentage of neutral airline tweets from US Airways is 0.13079299691040164

The percentage of positive airline tweets from US Airways is 0.7768623412289736

##Top 3 airlines with the highest percentage of positive tweets
1. Virgin America (30.2%)
2. Delta (24.5%)
3. Southwest (23.5%)

##Top 3 airlines with the highest percentage of negative tweets
1. USAirways (77.7%)
2. American (71.0)
3. United (68.9%)
"""